{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee9f429d",
   "metadata": {},
   "source": [
    "## Android app using Torch Model\n",
    "\n",
    "ref: https://pytorch.org/mobile/android/#quickstart-with-a-helloworld-example  \n",
    "(image segmentation https://pytorch.org/tutorials/beginner/deeplabv3_on_android.html)\n",
    "\n",
    "my repository: https://github.com/saugkim/TorchIntro/tree/main/Android/mobilenet\n",
    "\n",
    "project created 16.1.2022  \n",
    "Android studio IDE version: 4.2.1      \n",
    "org.pytorch:pytorch_android:1.10.0  \n",
    "minimum SDK version: 21  \n",
    "\n",
    "<br>\n",
    "\n",
    "build warning: possible issues!  <br>\n",
    "INSTALL_FAILED_INSUFFICIENT_STORAGE running on emulator (Nexus API 28)   \n",
    "The device needs more free storage to install the application (extra space is needed in addition to APK size).  \n",
    "  \n",
    "temp solution: wipe data AVD every time.....\n",
    "\n",
    "true solution: increase internal storage of android virtual device see below  \n",
    "\n",
    "   - press `Show Advanced Settings` button and scroll down to `Memory and Storage` part  \n",
    "   - change value of internal storage (default 800, Nexus 4 API 28) to 1500  \n",
    "   \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/saugkim/TorchIntro/main/Android/avd_setting1.PNG\" width=600 />\n",
    "<img src=\"https://raw.githubusercontent.com/saugkim/TorchIntro/main/Android/avd_setting2.PNG\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bd426",
   "metadata": {},
   "source": [
    "### step 1. conver PyTorch model to TorchScript format to use in android app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4057682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "model.eval()\n",
    "#example = torch.rand(1, 3, 224, 224)\n",
    "#traced_script_module = torch.jit.trace(model, example)\n",
    "#traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
    "#traced_script_module_optimized._save_for_lite_interpreter(\"app/src/main/assets/model.ptl\")\n",
    "scriptedm = torch.jit.script(model)\n",
    "torch.jit.save(scriptedm, \"mobilenet_scripted.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a218a52",
   "metadata": {},
   "source": [
    "###  Image Segmentation DeepLabV3 on Android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f02c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# use deeplabv3_resnet50 instead of resnet101 to reduce the model size\n",
    "model = torch.hub.load('pytorch/vision:v0.7.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "scriptedm = torch.jit.script(model)\n",
    "torch.jit.save(scriptedm, \"deeplabv3_scripted.pt\")\n",
    "\n",
    "\n",
    "example_image = \"https://raw.githubusercontent.com/jeffxtang/android-demo-app/new_demo_apps/ImageSegmentation/app/src/main/assets/deeplab.jpg\"\n",
    "\n",
    "input_image = Image.open(\"deeplab.jpg\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)['out'][0]\n",
    "\n",
    "print(input_batch.shape)\n",
    "print(output.shape)\n",
    "\n",
    "\n",
    "#output shoule be below:\n",
    "#\n",
    "#torch.Size([1, 3, 400, 400])\n",
    "#torch.Size([21, 400, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cce8b7",
   "metadata": {},
   "source": [
    "### step 2. Build a new Android app and add scripted torch Model and PyTorch Library on Android\n",
    "\n",
    "\n",
    "Saved model file *model_name.pt* to projectâ€™s assets folder.  \n",
    "\n",
    "        path to add model: app/src/main/assets/model_name.pt\n",
    "\n",
    "<br>\n",
    "\n",
    "Open build.gradle module file, and add the following two libraries in dependencies    \n",
    "\n",
    "\n",
    "*build.gradle(Module: appname.app)*  \n",
    "midSdkVersion 21 for torch 1.10.0 required  \n",
    "\n",
    "```    \n",
    "    \n",
    "    android {  \n",
    "        compileSdkVersion 31\n",
    "    \n",
    "        defaultConfig {\n",
    "            applicationId \"xxx.xxx.xxx\"\n",
    "            minSdkVersion 21\n",
    "            targetSdkVersion 31\n",
    "            versionCode 1\n",
    "            versionName \"1.0\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    dependencies {  \n",
    "        implementation 'org.pytorch:pytorch_android:1.10.0'   \n",
    "        implementation 'org.pytorch:pytorch_android_torchvision:1.10.0'   \n",
    "        ...  \n",
    "    } \n",
    "```\n",
    "   \n",
    "\n",
    "*build.gradle(Project: appname)*  \n",
    "   **jcenter() repository** cannot be removed at this moment - build error if removed:\n",
    "    \n",
    "```\n",
    "    allproject {\n",
    "        repositories {\n",
    "            google()\n",
    "            mavenCentral()\n",
    "            jcenter() // Warning: this repository is going to shut down soon\n",
    "        }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53416b",
   "metadata": {},
   "source": [
    "### step 3. process model input and run model with input and get output\n",
    "\n",
    "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db85375",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inside onCreate() of MainActivity.java\n",
    "\n",
    "    # preparing input tensor\n",
    "    final Tensor inputTensor = TensorImageUtils.bitmapToFloat32Tensor(bitmap,\n",
    "        TensorImageUtils.TORCHVISION_NORM_MEAN_RGB, \n",
    "        TensorImageUtils.TORCHVISION_NORM_STD_RGB, \n",
    "        MemoryFormat.CHANNELS_LAST);\n",
    "\n",
    "    \n",
    "    ## RUN Interface\n",
    "    # running the model\n",
    "    final Tensor outputTensor = module.forward(IValue.from(inputTensor)).toTensor();\n",
    "    # getting tensor content as java array of floats\n",
    "    final float[] scores = outputTensor.getDataAsFloatArray();\n",
    "\n",
    "    \n",
    "    ## RESULT \n",
    "    # searching for the index with maximum score\n",
    "    float maxScore = -Float.MAX_VALUE;\n",
    "    int maxScoreIdx = -1;\n",
    "    for (int i = 0; i < scores.length; i++) {\n",
    "      if (scores[i] > maxScore) {\n",
    "        maxScore = scores[i];\n",
    "        maxScoreIdx = i;\n",
    "      }\n",
    "    }\n",
    "\n",
    "    String className = ImageNetClasses.IMAGENET_CLASSES[maxScoreIdx];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ece0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
